#Linear Regression with Gradient Descent

This python script explores multiple linear regression alternatives for minimizing the model hypothesis error of the relationship between features and the target of a large dataset. Since, in some cases, a baseline linear regression by itself can not reduce the error between expected target and actual target, we also focus on finding other possible ways to model the problems. This script focuses on linear regression with gradient descent (GD), feature normalization, regularization and polynomial regression. However, the best results achieved also involved a series of data alterations such as feature scaling, feature selection and discrete variable enconding.

##How to use

First it is necessary to change the training and testing sets to the desired dataset. Another important step is to configure the parameters such as alpha, maximum number of iterations, tolerance as well as the regularization parameter (lbd).


